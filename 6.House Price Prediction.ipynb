{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries,setting working directory and reading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory : \n",
      " C:\\Users\\manum\\Desktop\\Daily Study\\Kaggle_Competitions\\2.Sberbank Russian Housing Market - House Price Prediction\\Data \n",
      "\n",
      "Shape of the data :  (30471, 292)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-20</td>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-08-27</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>5700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>13100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>195</td>\n",
       "      <td>14</td>\n",
       "      <td>16331452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
       "0   1  2011-08-20       43     27.0    4.0        NaN       NaN         NaN   \n",
       "1   2  2011-08-23       34     19.0    3.0        NaN       NaN         NaN   \n",
       "2   3  2011-08-27       43     29.0    2.0        NaN       NaN         NaN   \n",
       "3   4  2011-09-01       89     50.0    9.0        NaN       NaN         NaN   \n",
       "4   5  2011-09-05       77     77.0    4.0        NaN       NaN         NaN   \n",
       "\n",
       "   num_room  kitch_sq  ...  cafe_count_5000_price_2500  \\\n",
       "0       NaN       NaN  ...                           9   \n",
       "1       NaN       NaN  ...                          15   \n",
       "2       NaN       NaN  ...                          10   \n",
       "3       NaN       NaN  ...                          11   \n",
       "4       NaN       NaN  ...                         319   \n",
       "\n",
       "  cafe_count_5000_price_4000 cafe_count_5000_price_high  \\\n",
       "0                          4                          0   \n",
       "1                          3                          0   \n",
       "2                          3                          0   \n",
       "3                          2                          1   \n",
       "4                        108                         17   \n",
       "\n",
       "   big_church_count_5000  church_count_5000  mosque_count_5000  \\\n",
       "0                     13                 22                  1   \n",
       "1                     15                 29                  1   \n",
       "2                     11                 27                  0   \n",
       "3                      4                  4                  0   \n",
       "4                    135                236                  2   \n",
       "\n",
       "   leisure_count_5000  sport_count_5000  market_count_5000  price_doc  \n",
       "0                   0                52                  4    5850000  \n",
       "1                  10                66                 14    6000000  \n",
       "2                   4                67                 10    5700000  \n",
       "3                   0                26                  3   13100000  \n",
       "4                  91               195                 14   16331452  \n",
       "\n",
       "[5 rows x 292 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd # data manipulation\n",
    "import numpy as np # linear Algebra and mathematics\n",
    "from sklearn.tree import DecisionTreeRegressor # importing the Decision Tree class\n",
    "from sklearn.ensemble import RandomForestRegressor # importing the RandomForest class\n",
    "from sklearn import preprocessing # help in data impuation(NaNs) and Categorical features encoding\n",
    "from sklearn.tree import export_graphviz # This function generates a GraphViz representation of the decision tree, which is then written into out_file\n",
    "import datetime as dt # will be useful to convert the date to number of days since some point\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import six # Six is a Python 2 and 3 compatibility library\n",
    "\n",
    "#Setting working Directory\n",
    "os.chdir('C:/Users/manum/Desktop/Daily Study/Kaggle_Competitions/2.Sberbank Russian Housing Market - House Price Prediction/Data')\n",
    "print('Working Directory :','\\n',os.getcwd(),'\\n')\n",
    "\n",
    "#Reading data\n",
    "df_train=pd.read_csv('C:/Users/manum/Desktop/Daily Study/Kaggle_Competitions/2.Sberbank Russian Housing Market - House Price Prediction/Data/train.csv')\n",
    "df_test=pd.read_csv('C:/Users/manum/Desktop/Daily Study/Kaggle_Competitions/2.Sberbank Russian Housing Market - House Price Prediction/Data/test.csv')\n",
    "df_macro=pd.read_csv('C:/Users/manum/Desktop/Daily Study/Kaggle_Competitions/2.Sberbank Russian Housing Market - House Price Prediction/Data/macro.csv')\n",
    "\n",
    "\n",
    "print('Shape of the data : ', df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "* Create a vector containing the ids for our predictions\n",
    "* Create a vector of the target variables in the training set\n",
    "* Create joint train and test set to make data wrangling quicker and consistent on train and test\n",
    "* Removing the id (could it be a useful source of leakage?)\n",
    "* Convert the date into a number (of days since some point)\n",
    "* Deal with categorical variables\n",
    "* Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector containing the id's for our predictions\n",
    "id_test=df_test.id\n",
    "\n",
    "#Create a vector of the target variables in the training set\n",
    "# Transform target variable so that loss function is correct (ie we will use RMSLE in place of RMSE)\n",
    "# ylog1p_train will be log(1+y),\n",
    "\"\"\"\n",
    "This transformation is primarily used to convert the non-linear target variable into linear target variable, so that the linear \n",
    "model works well with the data and the performance of the model with transformed target improves\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ylog1p_train = np.log1p(df_train['price_doc'].values)\n",
    "df_train = df_train.drop([\"price_doc\"], axis=1)\n",
    "\n",
    "# combine both training and test sets to make data wrangling quicker and consistent on train and test sets\n",
    "df_train['TrainOrTest']='Train'\n",
    "df_test['TrainOrTest']='Test'\n",
    "\n",
    "df_all=pd.concat([df_train,df_test])\n",
    "\n",
    "# Remove ID column\n",
    "df_all=df_all.drop('id',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp  timedelta\n",
      "0 2011-08-20          0\n",
      "1 2011-08-23          3\n",
      "2 2011-08-27          7\n",
      "3 2011-09-01         12\n",
      "4 2011-09-05         16\n"
     ]
    }
   ],
   "source": [
    "df_all['timestamp']=pd.to_datetime(df_all['timestamp'])\n",
    "fromDate = min(df_all['timestamp'])\n",
    "df_all['timedelta'] = (df_all['timestamp'] - fromDate).dt.days.astype(int)\n",
    "print(df_all[['timestamp', 'timedelta']].head())\n",
    "df_all.drop('timestamp', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a naive approach and assign a numeric value to each categorical feature in our training and test sets. Sklearn's preprocessing unit has a tool called LabelEncoder() which can do just that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_all.columns:\n",
    "    if df_all[c].dtype=='object':\n",
    "        lbl=preprocessing.LabelEncoder()\n",
    "        lbl.fit(df_all[c].tolist())\n",
    "        df_all[c]=lbl.transform(df_all[c].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing problems with NaN in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw from our EDA there were quite a lot of NaN in the data. Our model won't know what to do with these so we need to replace them with something sensible.\n",
    "\n",
    "There are quite a few options we can use - the mean, median, most_frequent, or a numeric value like 0. Playing with these will give different results, for now I have it set to use the mean.\n",
    "\n",
    "This uses the mean of the column in which the missing value is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life_sq                                   7559\n",
      "floor                                      167\n",
      "max_floor                                 9572\n",
      "material                                  9572\n",
      "build_year                               14654\n",
      "num_room                                  9572\n",
      "kitch_sq                                  9572\n",
      "state                                    14253\n",
      "preschool_quota                           8284\n",
      "school_quota                              8280\n",
      "hospital_beds_raion                      17859\n",
      "raion_build_count_with_material_info      6209\n",
      "build_count_block                         6209\n",
      "build_count_wood                          6209\n",
      "build_count_frame                         6209\n",
      "build_count_brick                         6209\n",
      "build_count_monolith                      6209\n",
      "build_count_panel                         6209\n",
      "build_count_foam                          6209\n",
      "build_count_slag                          6209\n",
      "build_count_mix                           6209\n",
      "raion_build_count_with_builddate_info     6209\n",
      "build_count_before_1920                   6209\n",
      "build_count_1921-1945                     6209\n",
      "build_count_1946-1970                     6209\n",
      "build_count_1971-1995                     6209\n",
      "build_count_after_1995                    6209\n",
      "metro_min_walk                              59\n",
      "metro_km_walk                               59\n",
      "railroad_station_walk_km                    59\n",
      "railroad_station_walk_min                   59\n",
      "ID_railroad_station_walk                    59\n",
      "cafe_sum_500_min_price_avg               16440\n",
      "cafe_sum_500_max_price_avg               16440\n",
      "cafe_avg_price_500                       16440\n",
      "cafe_sum_1000_min_price_avg               7746\n",
      "cafe_sum_1000_max_price_avg               7746\n",
      "cafe_avg_price_1000                       7746\n",
      "cafe_sum_1500_min_price_avg               5020\n",
      "cafe_sum_1500_max_price_avg               5020\n",
      "cafe_avg_price_1500                       5020\n",
      "green_part_2000                             19\n",
      "cafe_sum_2000_min_price_avg               2149\n",
      "cafe_sum_2000_max_price_avg               2149\n",
      "cafe_avg_price_2000                       2149\n",
      "cafe_sum_3000_min_price_avg               1173\n",
      "cafe_sum_3000_max_price_avg               1173\n",
      "cafe_avg_price_3000                       1173\n",
      "prom_part_5000                             270\n",
      "cafe_sum_5000_min_price_avg                425\n",
      "cafe_sum_5000_max_price_avg                425\n",
      "cafe_avg_price_5000                        425\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of missing value counts by column\n",
    "missing_val_count_by_column=(df_all.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n",
    "\n",
    "\"\"\"\n",
    "df_missing=df_all.isnull().sum(axis=0).reset_index()\n",
    "df_missing.columns=['ColumnName','MissingValuesCount']\n",
    "idx_ = df_missing['MissingValuesCount']>0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Get names of categorical columns with missing values  \n",
    "cat_cols_with_missing=[col for col in df_all.columns\n",
    "                  if df_all[col].isnull().any() and df_all[col].dtype=='object']\n",
    "\n",
    "\n",
    "\n",
    "#Get names of numerical columns with missing values \n",
    "\n",
    "num_cols_with_missing=[col for col in df_all.columns\n",
    "                  if df_all[col].isnull().any() and df_all[col].dtype!='object']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-aaf4415c3067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Fit the imputer using all of our data (but not any dates)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_indicator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             X = check_array(X, accept_sparse='csc', dtype=dtype,\n\u001b[1;32m--> 235\u001b[1;33m                             force_all_finite=force_all_finite, copy=self.copy)\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mve\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"could not convert\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mve\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Instantiate an imputer\n",
    "\n",
    "\"\"\"\n",
    "x['Age'].fillna(x['Age'].mean(), inplace=True) #single varaible can be fixed this way\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values='NaN', strategy = 'mean')\n",
    "\n",
    "# Replace infinite values by NaN, before imputing\n",
    "#df_all.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fit the imputer using all of our data (but not any dates)\n",
    "df_all=pd.DataFrame(imputer.fit_transform(df_all))\n",
    "\n",
    "\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df_all.values >= np.finfo(np.float64).max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
